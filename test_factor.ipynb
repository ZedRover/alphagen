{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import SharedArray as sa\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from alphagen.data.expression import *\n",
    "from alphagen_ocean.calculator_ import QLibStockDataCalculator\n",
    "from alphagen_ocean.stock_data_ import StockData\n",
    "from alphagen.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "cuda = torch.device(\"cuda:3\")\n",
    "data_test = StockData(\n",
    "    start_time=20210601,\n",
    "    end_time=20211201,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = \"checkpoints/ocean_lexpr8_lopt34_10_949_20230810173533/59392_steps_pool.json\"\n",
    "with open(path, \"r\") as f:\n",
    "    alpha = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$qcumvolume',\n",
       " '$qcne5d_spec_ret',\n",
       " 'Abs(Greater(DeStd($qsize_ret_l),Mad($qcne5d_spec_risk,10)))',\n",
       " '$qmoneyflow_pct_value_l',\n",
       " '$qintra_spreadavgmidp11',\n",
       " '$qsell_value_med_order_act',\n",
       " '$qcne5d_sizenl',\n",
       " '$qintra_deltanetbuy_5_stdev',\n",
       " '$qmoneyflow_pct_value',\n",
       " '$qbuy_value_large_order_act']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha[\"exprs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from alphagen.data.tree import ExpressionBuilder\n",
    "from alphagen.data.tokens import *\n",
    "\n",
    "builder = ExpressionBuilder()\n",
    "builder.add_token(FeatureToken(FeatureType.qsize_ret_diff))\n",
    "builder.add_token(OperatorToken(DeStd))\n",
    "builder.add_token(FeatureToken(FeatureType.qcne5d_spec_risk))\n",
    "builder.add_token(DeltaTimeToken(10))\n",
    "builder.add_token(OperatorToken(Mad))\n",
    "builder.add_token(OperatorToken(Greater))\n",
    "builder.add_token(OperatorToken(Abs))\n",
    "builder.is_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [0] * 10\n",
    "for i in range(10):\n",
    "    if alpha[\"exprs\"][i][0] == \"$\":\n",
    "        factors[i] = Feature(getattr(FeatureType, alpha[\"exprs\"][i][1:])).evaluate(\n",
    "            data_test\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors[2] = builder.get_tree().evaluate(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.Tensor(alpha[\"weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0190, -0.0354, -0.0127,  0.0106, -0.0159, -0.0098, -0.0090, -0.0092,\n",
       "         0.0150,  0.0178])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_value = torch.zeros_like(factors[0])\n",
    "for i in range(10):\n",
    "    factor_value += factors[i] * weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphagen.utils.pytorch_utils import normalize_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = normalize_by_day(factor_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem of retx:84.136962890625 MB\n"
     ]
    }
   ],
   "source": [
    "cal_test = QLibStockDataCalculator(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1d = cal_test.ret1d\n",
    "y2d = cal_test.ret2d\n",
    "y5d = cal_test.ret5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphagen.utils.correlation import batch_pearsonr, batch_spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pearsonr cost 0.38831043243408203 seconds\n",
      "tensor(0.0080, dtype=torch.float64)\n",
      "batch_spearmanr cost 548.7186081409454 seconds\n",
      "tensor(0.0503)\n",
      "batch_pearsonr cost 0.1422739028930664 seconds\n",
      "tensor(0.0100, dtype=torch.float64)\n",
      "batch_spearmanr cost 574.142594575882 seconds\n",
      "tensor(0.0490)\n",
      "batch_pearsonr cost 0.09109711647033691 seconds\n",
      "tensor(0.0100, dtype=torch.float64)\n",
      "batch_spearmanr cost 572.6553502082825 seconds\n",
      "tensor(0.0490)\n"
     ]
    }
   ],
   "source": [
    "for y in [y1d, y2d, y5d]:\n",
    "    print(torch.mean(batch_pearsonr(yhat, y)))\n",
    "    print(torch.mean(batch_spearmanr(yhat, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pearsonr cost 0.005568504333496094 seconds\n",
      "tensor(0.0080, device='cuda:1', dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 61.62 GiB (GPU 1; 11.77 GiB total capacity; 305.01 MiB already allocated; 9.37 GiB free; 318.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/ray/workspace/alphagen/test_factor.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bray/home/ray/workspace/alphagen/test_factor.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m [y1d,y2d,y5d]:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bray/home/ray/workspace/alphagen/test_factor.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mmean(batch_pearsonr(yhat\u001b[39m.\u001b[39mto(cuda),y\u001b[39m.\u001b[39mto(cuda))))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bray/home/ray/workspace/alphagen/test_factor.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mmean(batch_spearmanr(yhat\u001b[39m.\u001b[39;49mto(cuda),y\u001b[39m.\u001b[39;49mto(cuda))))\n",
      "File \u001b[0;32m~/workspace/alphagen/alphagen/utils/correlation.py:44\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m cost \u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/workspace/alphagen/alphagen/utils/correlation.py:54\u001b[0m, in \u001b[0;36mbatch_spearmanr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m x, y, n, nan_mask \u001b[39m=\u001b[39m _mask_either_nan(x, y)\n\u001b[1;32m     53\u001b[0m rx \u001b[39m=\u001b[39m _rank_data(x, nan_mask)\n\u001b[0;32m---> 54\u001b[0m ry \u001b[39m=\u001b[39m _rank_data(y, nan_mask)\n\u001b[1;32m     55\u001b[0m \u001b[39mreturn\u001b[39;00m _batch_pearsonr_given_mask(rx, ry, n, nan_mask)\n",
      "File \u001b[0;32m~/workspace/alphagen/alphagen/utils/correlation.py:19\u001b[0m, in \u001b[0;36m_rank_data\u001b[0;34m(x, nan_mask)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rank_data\u001b[39m(x: Tensor, nan_mask: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     18\u001b[0m     rank \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39margsort()\u001b[39m.\u001b[39margsort()\u001b[39m.\u001b[39mfloat()  \u001b[39m# [d, s]\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     eq \u001b[39m=\u001b[39m x[:, \u001b[39mNone\u001b[39;49;00m] \u001b[39m==\u001b[39;49m x[:, :, \u001b[39mNone\u001b[39;49;00m]  \u001b[39m# [d, s, s]\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     eq \u001b[39m=\u001b[39m eq \u001b[39m/\u001b[39m eq\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# [d, s, s]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     rank \u001b[39m=\u001b[39m (eq \u001b[39m@\u001b[39m rank[:, :, \u001b[39mNone\u001b[39;00m])\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 61.62 GiB (GPU 1; 11.77 GiB total capacity; 305.01 MiB already allocated; 9.37 GiB free; 318.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "cuda = torch.device(\"cuda:1\")\n",
    "for y in [y1d, y2d, y5d]:\n",
    "    print(torch.mean(batch_pearsonr(yhat.to(cuda), y.to(cuda))))\n",
    "    print(torch.mean(batch_spearmanr(yhat.to(cuda), y.to(cuda))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphagen.data.tree import ExpressionBuilder\n",
    "from alphagen.data.tokens import *\n",
    "from alphagen_ocean.stock_data_ import FeatureType\n",
    "from ocean_common.feature_list import FEATURES\n",
    "from alphagen.config import *\n",
    "\n",
    "\n",
    "def tokenize_formula(formula: str) -> List[str]:\n",
    "    # This is a simple tokenizer. For more complex formulas, you might want to use regex or other methods.\n",
    "    tokens = []\n",
    "    token = \"\"\n",
    "    for char in formula:\n",
    "        if char in [\"(\", \")\", \",\"]:\n",
    "            if token:\n",
    "                tokens.append(token)\n",
    "                token = \"\"\n",
    "            tokens.append(char)\n",
    "        else:\n",
    "            token += char\n",
    "    if token:\n",
    "        tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def formula_to_expression(\n",
    "    formula: str,\n",
    "    operators: List[Type[Operator]] = OPERATORS,\n",
    "    features: List[FeatureType] = FEATURES,\n",
    ") -> Expression:\n",
    "    # Tokenize the formula\n",
    "    tokens = tokenize_formula(formula)\n",
    "\n",
    "    # Create an ExpressionBuilder\n",
    "    builder = ExpressionBuilder()\n",
    "\n",
    "    # Convert tokens to ExpressionBuilder tokens and add them\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"$\"):\n",
    "            feature_type = getattr(FeatureType, token[1:])\n",
    "            if feature_type in features:\n",
    "                builder.add_token(FeatureToken(feature_type))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown feature: {token}\")\n",
    "        elif token.isdigit() or (token[0] == \"-\" and token[1:].isdigit()):\n",
    "            builder.add_token(DeltaTimeToken(int(token)))\n",
    "        else:\n",
    "            operator_class = next(\n",
    "                (op for op in operators if op.__name__ == token), None\n",
    "            )\n",
    "            if operator_class:\n",
    "                builder.add_token(OperatorToken(operator_class))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown operator: {token}\")\n",
    "\n",
    "    if not builder.is_valid():\n",
    "        raise ValueError(\"Invalid formula\")\n",
    "\n",
    "    return builder.get_tree()\n",
    "\n",
    "\n",
    "# Test\n",
    "formula = \"Abs(Greater(DeStd($qsize_ret_l),Mad($qcne5d_spec_risk,10)))\"\n",
    "operators = [Abs, Greater, DeStd, Mad]\n",
    "features = list(FeatureType)\n",
    "expression = formula_to_expression(formula, operators, features)\n",
    "print(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
